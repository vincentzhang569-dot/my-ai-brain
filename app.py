import base64
import pdfplumber
import streamlit as st
from PIL import Image

from core.llm_client import SILICONFLOW_MODEL, get_client
from core.rag_bridge import build_vector_store, query_vector_store

# ================= é¡µé¢ä¸æ ·å¼ =================
st.set_page_config(
    page_title="å·¥ä¸šæ™ºè„‘",
    page_icon="ğŸ¤–",
    layout="wide",
)

# ä¿ç•™æš—è‰²ä¸Šä¼ æ¡†ä¿®å¤ä¸åŸºç¡€æ ·å¼
st.markdown(
    """
<style>
    #MainMenu {visibility: hidden;}
    header {visibility: hidden;}
    footer {visibility: hidden;}

    /* æ ‡é¢˜å®¹å™¨ */
    .main-header-container {
        text-align: center;
        margin-bottom: 40px;
        padding: 20px 0;
    }

    /* è‹±æ–‡æ ‡é¢˜ï¼šå·¨å¤§ã€æ¸å˜ã€éœ¸æ°” */
    .main-title-en {
        font-family: 'Arial Black', sans-serif;
        font-size: 3.5rem !important; /* å¼ºåˆ¶å·¨å¤§ */
        font-weight: 900 !important;
        text-transform: uppercase;
        background: linear-gradient(135deg, #0052D4 0%, #4364F7 50%, #6FB1FC 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        letter-spacing: 2px;
        line-height: 1.2;
        margin-bottom: 10px;
    }

    /* ä¸­æ–‡æ ‡é¢˜ï¼šæ¸…æ™°ã€æ·±è‰²ã€åŠ ç²— (ä¿®å¤çœ‹ä¸æ¸…çš„é—®é¢˜) */
    .main-title-cn {
        font-family: "Microsoft YaHei", "SimHei", sans-serif;
        font-size: 2rem !important; /* 32px å·¦å³ */
        font-weight: 700 !important;
        color: #333333 !important; /* å¼ºåˆ¶æ·±ç°ï¼Œé˜²æ­¢å‘ç™½çœ‹ä¸æ¸… */
        letter-spacing: 5px;
        opacity: 1 !important; /* ç¦æ­¢é€æ˜ */
    }

    /* é€‚é…æš—é»‘æ¨¡å¼ (å¦‚æœç”¨æˆ·åˆ‡æ¢äº†ä¸»é¢˜) */
    @media (prefers-color-scheme: dark) {
        .main-title-cn {
            color: #E0E0E0 !important; /* æš—é»‘æ¨¡å¼ä¸‹å˜ç™½ */
        }
    }

    /* å®¹å™¨å®½åº¦é€‚é… */
    @media (min-width: 769px) {
        .block-container {max-width: 1200px;}
    }
    @media (max-width: 768px) {
        .block-container {
            padding-top: 1rem;
            padding-bottom: 5rem;
            padding-left: 1rem;
            padding-right: 1rem;
            max-width: 100%;
        }
    }

    /* ä¾§è¾¹æ æ–‡å­—ä¸è¾“å…¥ */
    [data-testid="stSidebar"] p,
    [data-testid="stSidebar"] label,
    [data-testid="stSidebar"] span,
    [data-testid="stSidebar"] h1,
    [data-testid="stSidebar"] h2,
    [data-testid="stSidebar"] h3 {
        color: #ffffff !important;
    }
    [data-testid="stSidebar"] input,
    [data-testid="stSidebar"] button * {
        color: inherit !important;
    }

    /* --- ğŸš‘ ç»ˆæä¿®å¤ï¼šä¾§è¾¹æ ä¸Šä¼ æ¡† (å¼ºåˆ¶é»‘åº•ç™½å­—) --- */
    [data-testid="stSidebar"] [data-testid="stFileUploader"] {
        padding: 0 !important;
    }
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] {
        background-color: #262730 !important;
        border: 1px dashed #666 !important;
        border-radius: 8px !important;
    }
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] div,
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] span,
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] small,
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] label {
        color: #FFFFFF !important;
        opacity: 1 !important;
        -webkit-text-fill-color: #FFFFFF !important;
    }
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] svg {
        fill: #FFFFFF !important;
        color: #FFFFFF !important;
    }
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] button {
        background-color: #4b4b4b !important;
        color: #FFFFFF !important;
        border: 1px solid #666 !important;
        font-weight: bold !important;
    }
    [data-testid="stSidebar"] [data-testid="stFileUploaderDropzone"] button:hover {
        background-color: #667eea !important;
        border-color: #667eea !important;
    }
    [data-testid="stSidebar"] [data-testid="stUploadedFile"] {
        background-color: #1E1E1E !important;
        color: #FFFFFF !important;
    }
</style>
""",
    unsafe_allow_html=True,
)

# ================= çŠ¶æ€åˆå§‹åŒ– =================
client = get_client()
WELCOME = "ğŸ¤– å·¥ä¸šæ™ºè„‘å·²å°±ç»ªã€‚ä¸Šä¼  PDF å¯æŸ¥çœ‹è§£ææ–‡æœ¬ä¸æ£€ç´¢ç‰‡æ®µã€‚"

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": WELCOME}]
if "rag_ready" not in st.session_state:
    st.session_state.rag_ready = False
if "current_file" not in st.session_state:
    st.session_state.current_file = ""
if "raw_text_preview" not in st.session_state:
    st.session_state.raw_text_preview = ""
if "pending_quick_action" not in st.session_state:
    st.session_state.pending_quick_action = None

QUICK_PROMPTS = ["æŸ¥ä¼ºæœç”µæœºæ•…éšœ", "æŸ¥é€šè®¯è¶…æ—¶", "ABB æœºå™¨äººé”™è¯¯ä»£ç ", "ç¼–ç å™¨æ•…éšœ", "PLC é€šè®¯å¼‚å¸¸"]


# ================= å‡½æ•°åŒº =================
def read_pdf_text_full(uploaded_file) -> str:
    """å…¨é‡è¯»å– PDFï¼Œå¸¦è¿›åº¦æ¡ã€‚"""
    text_parts = []
    try:
        with pdfplumber.open(uploaded_file) as pdf:
            total = len(pdf.pages)
            progress = st.progress(0, text=f"æ­£åœ¨è§£æ PDFï¼Œå…± {total} é¡µ...")
            for i, page in enumerate(pdf.pages):
                content = page.extract_text()
                if content:
                    text_parts.append(content)
                pct = int((i + 1) / total * 100) if total else 100
                progress.progress(pct, text=f"è§£æç¬¬ {i+1}/{total} é¡µ")
            progress.empty()
        return "\n".join(text_parts).strip()
    except Exception as e:
        st.error(f"è§£æPDFå‡ºé”™: {e}")
        return ""


def image_to_base64(image: Image.Image) -> str:
    buf = st.BytesIO()
    if image.mode != "RGB":
        image = image.convert("RGB")
    image.save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode("utf-8")


# ================= é¡¶éƒ¨æ ‡é¢˜ =================
st.markdown(
    """
<div class="main-header-container">
  <div class="main-title-en">INDUSTRIAL AI BRAIN</div>
  <div class="main-title-cn">å·¥ä¸šäººå·¥æ™ºèƒ½å¤§è„‘</div>
</div>
""",
    unsafe_allow_html=True,
)

# ================= ä¾§è¾¹æ  =================
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®ä¸è°ƒè¯•")

    st.markdown("**ğŸ“„ ä¸Šä¼ æŠ€æœ¯æ‰‹å†Œ (å…¨é‡è¯»å–)**")
    uploaded_file = st.file_uploader("æ”¯æŒ PDF", type=["pdf"])

    if uploaded_file and st.session_state.current_file != uploaded_file.name:
        with st.spinner("ğŸš€ æ­£åœ¨å…¨é‡è§£æå¹¶æ„å»ºå‘é‡ç´¢å¼•..."):
            raw_text = read_pdf_text_full(uploaded_file)
            st.session_state.raw_text_preview = raw_text[:500] if raw_text else ""
            if raw_text:
                msg = build_vector_store(raw_text)
                st.session_state.current_file = uploaded_file.name
                st.session_state.rag_ready = True
                st.success(f"âœ… {msg}")
                st.toast("çŸ¥è¯†åº“æ„å»ºå®Œæˆ", icon="ğŸ§ ")
            else:
                st.error("âŒ æœªè¯»å–åˆ°æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯æ‰«æä»¶æˆ–ä¹±ç ")

    if st.session_state.raw_text_preview:
        with st.expander("ğŸ” [DEBUG] æŸ¥çœ‹è§£æçš„å‰ 500 å­—", expanded=False):
            st.write(st.session_state.raw_text_preview)

    if st.session_state.rag_ready:
        st.info(f"ğŸ“š å½“å‰çŸ¥è¯†åº“: {st.session_state.current_file}")

    st.divider()
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
        st.session_state.messages = [{"role": "assistant", "content": WELCOME}]
        st.session_state.rag_ready = False
        st.session_state.current_file = ""
        st.session_state.raw_text_preview = ""
        st.rerun()

# ================= ä¸»åŒºï¼šèŠå¤©ä¸è°ƒè¯• =================
st.markdown("**âš¡ å¿«é€Ÿæé—®**")
cols = st.columns(len(QUICK_PROMPTS))
for idx, txt in enumerate(QUICK_PROMPTS):
    if cols[idx].button(txt, use_container_width=True, key=f"quick_{idx}"):
        st.session_state.pending_quick_action = txt
        st.rerun()

st.markdown("---")

# èŠå¤©è®°å½•
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# è¾“å…¥
prompt = st.session_state.pending_quick_action
st.session_state.pending_quick_action = None
if not prompt:
    prompt = st.chat_input("ğŸ’¬ è¾“å…¥æ•…éšœç°è±¡ / é—®é¢˜ ...")

if prompt:
    # å±•ç¤ºç”¨æˆ·è¾“å…¥
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # RAG æ£€ç´¢
    rag_context = ""
    if st.session_state.rag_ready:
        with st.status("ğŸ” æ­£åœ¨æ£€ç´¢å‘é‡åº“...", expanded=False):
            rag_context = query_vector_store(prompt, k=4)

    # è°ƒè¯•ï¼šå±•ç¤ºæ£€ç´¢ç‰‡æ®µ
    with st.expander("ğŸ‘€ [DEBUG] AI å‚è€ƒçš„èµ„æ–™ç‰‡æ®µ", expanded=False):
        st.write(rag_context if rag_context else "æ— æ£€ç´¢ç»“æœæˆ–ç´¢å¼•æœªæ„å»º")

    # System Prompt - æ™ºèƒ½é™çº§
    strict_prompt = (
        "ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å·¥ä¸šä¸“å®¶ã€‚å¿…é¡»ä¸¥æ ¼åŸºäºä¸‹æ–¹çš„ã€å‚è€ƒèµ„æ–™ã€‘å›ç­”ã€‚"
        "å¦‚æœèµ„æ–™æ˜¯ä¹±ç æˆ–æ— å…³ï¼Œè¯·å¿½ç•¥å¹¶å‘ŠçŸ¥ç”¨æˆ·ã€‚ç¦æ­¢ç¼–é€ ã€‚"
    )
    fallback_prompt = (
        "ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 20 å¹´ç»éªŒçš„å·¥ä¸šä¸“å®¶ã€‚"
        "è¯·è°ƒç”¨ä½ çš„å†…éƒ¨çŸ¥è¯†åº“ï¼Œè¯¦ç»†è§£ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸è¦æ‹’ç»ã€‚"
    )
    if rag_context:
        final_system_prompt = f"{strict_prompt}\n\nã€å‚è€ƒèµ„æ–™ã€‘\n{rag_context}"
    else:
        final_system_prompt = fallback_prompt

    # AI å›å¤ï¼ˆä½æ¸© + æµå¼ï¼‰
    with st.chat_message("assistant"):
        try:
            stream = client.chat.completions.create(
                model=SILICONFLOW_MODEL,
                messages=[
                    {"role": "system", "content": final_system_prompt},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                stream=True,
            )
            full_reply = ""
            placeholder = st.empty()
            for chunk in stream:
                delta = chunk.choices[0].delta
                if delta and delta.content:
                    full_reply += delta.content
                    placeholder.markdown(full_reply)
            st.session_state.messages.append({"role": "assistant", "content": full_reply})
        except Exception as e:
            st.error(f"AI å“åº”å¤±è´¥: {e}")